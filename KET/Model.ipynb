{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import TransfoXLTokenizer, TransfoXLModel, TransfoXLLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.models import MultiHeadRelativeAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransfoXLLMHeadModel??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1140884800/1140884800 [02:23<00:00, 7956250.36B/s]\n",
      "100%|██████████| 606/606 [00:00<00:00, 463062.17B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransfoXLLMHeadModel(\n",
       "  (transformer): TransfoXLModel(\n",
       "    (word_emb): AdaptiveEmbedding(\n",
       "      (emb_layers): ModuleList(\n",
       "        (0): Embedding(20000, 1024)\n",
       "        (1): Embedding(20000, 256)\n",
       "        (2): Embedding(160000, 64)\n",
       "        (3): Embedding(67735, 16)\n",
       "      )\n",
       "      (emb_projs): ParameterList(\n",
       "          (0): Parameter containing: [torch.FloatTensor of size 1024x1024]\n",
       "          (1): Parameter containing: [torch.FloatTensor of size 1024x256]\n",
       "          (2): Parameter containing: [torch.FloatTensor of size 1024x64]\n",
       "          (3): Parameter containing: [torch.FloatTensor of size 1024x16]\n",
       "      )\n",
       "    )\n",
       "    (drop): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (1): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (2): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (3): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (4): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (5): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (6): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (7): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (8): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (9): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (10): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (11): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (12): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (13): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (14): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (15): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (16): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (17): RelPartialLearnableDecoderLayer(\n",
       "        (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (drop): Dropout(p=0.1)\n",
       "          (dropatt): Dropout(p=0.0)\n",
       "          (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (layer_norm): BertLayerNorm()\n",
       "          (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (pos_ff): PositionwiseFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "          )\n",
       "          (layer_norm): BertLayerNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "  )\n",
       "  (crit): ProjectedAdaptiveLogSoftmax(\n",
       "    (out_layers): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=20000, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=20000, bias=True)\n",
       "      (2): Linear(in_features=64, out_features=160000, bias=True)\n",
       "      (3): Linear(in_features=16, out_features=67735, bias=True)\n",
       "    )\n",
       "    (out_projs): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 1024x1024]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 1024x256]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 1024x64]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 1024x16]\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransfoXLLMHeadModel.from_pretrained('transfo-xl-wt103')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9143613/9143613 [00:02<00:00, 4396097.96B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary from wikitext 103)\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')\n",
    "\n",
    "# Tokenized input\n",
    "text_1 = \"Who was Jim Henson ?\"\n",
    "text_2 = \"Jim Henson was a puppeteer\"\n",
    "tokenized_text_1 = tokenizer.tokenize(text_1)\n",
    "tokenized_text_2 = tokenizer.tokenize(text_2)\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokenized_text_1)\n",
    "indexed_tokens_2 = tokenizer.convert_tokens_to_ids(tokenized_text_2)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor_1 = torch.tensor([indexed_tokens_1])\n",
    "tokens_tensor_2 = torch.tensor([indexed_tokens_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor_1 = tokens_tensor_1.to('cpu')\n",
    "tokens_tensor_2 = tokens_tensor_2.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Predict all tokens\n",
    "    predictions_1, mems_1 = model(tokens_tensor_1)\n",
    "    # We can re-use the memory cells in a subsequent call to attend a longer context\n",
    "    predictions_2, mems_2 = model(tokens_tensor_2, mems=mems_1)\n",
    "\n",
    "# get the predicted last token\n",
    "predicted_index = list(map(lambda x:x.item(),predictions_2[0, :, :].argmax(1)))\n",
    "predicted_token = tokenizer.convert_ids_to_tokens(predicted_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden_2, mems_2 = model.transformer(tokens_tensor_2, mems=mems_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1024])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaskedKnowledgeAGG(torch.nn.module):\n",
    "    def __init__(self,\n",
    "                 vocab_sz:int,\n",
    "                 d_model:int,\n",
    "                 d_head:int,\n",
    "                 n_heads:int,\n",
    "                 embed_p:float=0.,\n",
    "                 d_head_ent:int,\n",
    "                 n_heads_ent:int,\n",
    "                 embed_p_ent:float=0.,\n",
    "                 d_ent:int,\n",
    "                 mem_len:int,\n",
    "                 n_layers:int,\n",
    "                 mask:bool=True,\n",
    "                 ent_vocab_sz:int,\n",
    "                 d_inner:int\n",
    "                 \n",
    "                ):\n",
    "        super().__init__()\n",
    "        # get id as inputs and outputs vectors\n",
    "        self.token_enc = nn.Embedding(vocab_sz, d_model)\n",
    "        self.ent_enc = nn.Embedding(ent_vocab_sz, d_ent)\n",
    "        self.pos_enc_tokens = nn.Embedding(ctx_len, d_model)\n",
    "        self.pos_enc_ent = nn.Embedding(ctx_len, d_ent)\n",
    "        self.drop_emb_token = nn.Dropout(embed_p)\n",
    "        self.drop_emb_ent = nn.Dropout(embed_p_ent)\n",
    "\n",
    "        self.u_tkn = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "        self.u_ent = nn.Parameter(torch.Tensor(n_heads_ent, 1, d_head_ent)) #Remove 1 for einsum implementation of attention\n",
    "\n",
    "        self.v_tkn = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "        self.v_ent = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "\n",
    "        self.mem_len,self.n_layers,self.d_model,self.mask = mem_len,n_layers,d_model,mask\n",
    "        self.init = False\n",
    "        self.ent_attention =[]\n",
    "        self.tkn_attention = []\n",
    "        for layer in layers:\n",
    "            ent_attention.append(DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                      ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                      attn_cls=attn_cls))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mems_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1600, 1, 1024])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mems_2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Henson', '?', 'in', 'man', 'who']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12034, 788, 7, 435, 52]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x:x.item(),predictions_2[0, :, :].argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267735"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Environment (conda_fastai)",
   "language": "python",
   "name": "conda_fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
